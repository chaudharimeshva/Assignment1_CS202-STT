{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tcl6AcjIBRi",
        "outputId": "4f54e2b1-32c3-4c15-fe66-0a58799db6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'jinja' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pallets/jinja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY3T8vakIRcs",
        "outputId": "c23a1344-c97d-4ee2-b184-e9d74f2bea09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydriller\n",
            "  Downloading pydriller-2.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.12/dist-packages (from pydriller) (3.1.45)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from pydriller) (2025.2)\n",
            "Requirement already satisfied: types-pytz in /usr/local/lib/python3.12/dist-packages (from pydriller) (2025.2.0.20250809)\n",
            "Collecting lizard==1.17.10 (from pydriller)\n",
            "  Downloading lizard-1.17.10-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython->pydriller) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.2)\n",
            "Downloading pydriller-2.8-py3-none-any.whl (36 kB)\n",
            "Downloading lizard-1.17.10-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lizard, pydriller\n",
            "Successfully installed lizard-1.17.10 pydriller-2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pydriller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OeBcGU2gzQYV"
      },
      "outputs": [],
      "source": [
        "from pydriller import Repository\n",
        "import csv\n",
        "\n",
        "Path=r\"/content/jinja\"\n",
        "\n",
        "with open(\"commits_info.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    file=csv.writer(f)\n",
        "    file.writerow([\"Hash\", \"Message\", \"Hashes of parents\", \"Is a merge commit?\", \"List of modified files\"])\n",
        "\n",
        "    commits=Repository(Path).traverse_commits()\n",
        "    for i in commits:\n",
        "        commit=i.msg.lower()\n",
        "\n",
        "        for j in commit.split():\n",
        "            found=False;\n",
        "            if j in ['fix', 'bug', 'issue', 'patch', 'resolve', 'error', 'correct', 'repair']:\n",
        "                file.writerow([i.hash,i.msg,[k for k in i.parents],i.merge,[new_file.new_path for new_file in i.modified_files]])\n",
        "                found=True\n",
        "                break\n",
        "            if found:\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "j-1Ej0RUJNjX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtHMmZ2HIr4r",
        "outputId": "f84bc455-e00d-463e-f1f7-69cf7bcccdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Hash', 'Message', 'Hashes of parents', 'Is a merge commit?',\n",
            "       'List of modified files'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv(r\"/content/commits_info.csv\")\n",
        "name=df.columns\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orkucymlKd_V",
        "outputId": "1c174b31-743a-453f-a17a-2b03a88a43ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NThPHdQnH-2c",
        "outputId": "7ac039e0-8670-4449-844f-c58d49709689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perfoming task-d !\n",
            "Generating LLM_Inference (file name)\n",
            "\n",
            "By the use of LLM CommitPridictoreT5\n",
            "\n",
            "Generating Rectifier message by the use of LLM model codet5-large\n",
            "\n",
            "cuda\n",
            "Final Step 5\n",
            "\n",
            "Lab2_Final.csv made Successfully...!\n"
          ]
        }
      ],
      "source": [
        "from pydriller import Repository\n",
        "import csv\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "Path=r\"/content/jinja\"\n",
        "Task_c=r\"/content/commits_info.csv\"\n",
        "\n",
        "\n",
        "# Loading bug_fixing_commit hashes:\n",
        "print(\"Perfoming task-d !\")\n",
        "hashes={i[\"Hash\"] for i in csv.DictReader(open(Task_c, encoding=\"utf-8\"))}\n",
        "\n",
        "\n",
        "print(\"Generating LLM_Inference (file name)\")\n",
        "print()\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
        "model=AutoModelForSeq2SeqLM.from_pretrained(\"mamiksik/CommitPredictorT5\")\n",
        "\n",
        "print(\"By the use of LLM CommitPridictoreT5\")\n",
        "print()\n",
        "\n",
        "def llm_commit(i: str)->str:\n",
        "    if(i.strip()):\n",
        "        input=tokenizer(i,return_tensors=\"pt\", truncation=True, max_length=500)\n",
        "        output=model.generate(**input, max_length=70)\n",
        "\n",
        "        return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "print(\"Generating Rectifier message by the use of LLM model codet5-large\")\n",
        "print()\n",
        "\n",
        "model_name_rectifier = \"Salesforce/codet5-small\"  # Or \"Salesforce/codet5-large\"\n",
        "tokenizer_rectifier = AutoTokenizer.from_pretrained(model_name_rectifier)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model_rectifier = AutoModelForSeq2SeqLM.from_pretrained(model_name_rectifier).to(device)\n",
        "\n",
        "def generate_rectified_message(diff_text: str, original_msg: str) -> str:\n",
        "    \"\"\"Generate rectified commit message using CodeT5.\"\"\"\n",
        "    if not diff_text.strip():\n",
        "        return \"[No diff to analyze]\"\n",
        "    try:\n",
        "        prompt = f\"Original commit message: {original_msg}\\nCode changes:\\n{diff_text}\\n\\nGenerate a detailed and precise commit message describing all changes:\"\n",
        "\n",
        "        inputs = tokenizer_rectifier(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(device)\n",
        "\n",
        "        outputs = model_rectifier.generate(\n",
        "            **inputs,\n",
        "            max_length=64,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        return tokenizer_rectifier.decode(outputs[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        return f\"[Error generating rectifier message: {e}]\"\n",
        "def rectifier(message: str, filename: str, i: str, llm: str)->str:\n",
        "    msg=message.strip()\n",
        "    sample_msgs=[\"fix bug\", \"fixed bugs\", \"bug fix\", \"minor fix\", \"fix errors\"]\n",
        "    if(len(msg.split())<3 or msg.lower() in sample_msgs) and llm:\n",
        "        return llm\n",
        "\n",
        "    if filename and \"test\" in filename.lower():\n",
        "        return f\"{llm} (test-related)\" if llm else f\"{msg} (test-related)\"\n",
        "    if filename and \"parser\" in filename.lower():\n",
        "        return f\"{llm} (parser-related)\" if llm else f\"{msg} (parser-related)\"\n",
        "\n",
        "    return msg\n",
        "\n",
        "print(\"Final Step 5\")\n",
        "print()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Lab2_Final.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    file=csv.writer(f)\n",
        "    file.writerow([\"Hash\", \"Message\", \"Filename\", \"Source Code (before)\", \"Source Code (current)\", \"Diff\", \"LLM Inference (fix type)\", \"Rectified Message\"])\n",
        "\n",
        "    for i in Repository(Path).traverse_commits():\n",
        "        if i.hash not in hashes:\n",
        "            continue\n",
        "\n",
        "        for j in i.modified_files:\n",
        "            File=j.new_path if j.new_path else \"\"\n",
        "            difference=j.diff if j.diff else \"\"\n",
        "\n",
        "            if not File.endswith(\".py\"):\n",
        "                continue\n",
        "            if not j.source_code_before or not j.source_code:\n",
        "                continue\n",
        "            if not difference.strip():\n",
        "                continue\n",
        "\n",
        "            llm=llm_commit(difference)\n",
        "            rectified=rectifier(i.msg, File, difference, llm)\n",
        "\n",
        "            file.writerow([i.hash, i.msg.strip(), File, j.source_code_before if j.source_code_before else \"\", j.source_code if j.source_code else \"\", difference, llm, rectified])\n",
        "\n",
        "print(\"Lab2_Final.csv made Successfully...!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}